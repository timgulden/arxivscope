# Next Steps After Migration ‚úÖ

**Migration completed**: October 10, 2025  
**Status**: Database streamlined, API running, ready for frontend testing

---

## ‚úÖ What Was Completed

1. ‚úÖ Stopped the inefficient DELETE operation (was running 1+ hour with minimal progress)
2. ‚úÖ Created new optimized table with only arxiv/RAND data (2.9M rows)
3. ‚úÖ Built all 12 indexes on new table
4. ‚úÖ Atomically swapped tables (downtime: ~2 minutes)
5. ‚úÖ Restarted API server - **currently healthy**
6. ‚úÖ Preserved old table as `doctrove_papers_old` for safety

---

## üéØ Immediate Actions (Next 1-2 Hours)

### 1. Start Frontend and Test

```bash
# Start React frontend
cd /opt/arxivscope/docscope-platform/services/docscope/react
npm run dev
```

Access at: http://localhost:8052

### 2. Test Core Functionality

Test these features:
- ‚úÖ Home page loads
- ‚úÖ Papers display correctly
- ‚úÖ Search works
- ‚úÖ Filter by source (should show: arxiv, randpub, extpub only)
- ‚úÖ Date filtering
- ‚úÖ Vector similarity search (if used)
- ‚úÖ 2D visualization/clustering (if used)

### 3. Verify Data Quality

Quick database checks:
```bash
# Check row counts by source
PGPASSWORD=doctrove_admin psql -h localhost -p 5434 -U doctrove_admin -d doctrove -c \
  "SELECT doctrove_source, COUNT(*), 
   MIN(doctrove_primary_date) as earliest, 
   MAX(doctrove_primary_date) as latest 
   FROM doctrove_papers 
   GROUP BY doctrove_source 
   ORDER BY COUNT(*) DESC;"

# Expected results:
# arxiv:   2,837,412 papers (1986-2025)
# randpub:    71,622 papers (1945-2025)
# extpub:     10,221 papers (1952-2025)
```

---

## ‚è∞ Short-Term Actions (Next 24-48 Hours)

### Monitor Performance
- Watch for any slow queries
- Check API logs: `screen -r doctrove_api` or `tail -f doctrove-api/api.log`
- Monitor system resources: `htop` or `top`

### Test Edge Cases
- Very large date ranges
- Complex search queries
- All filter combinations
- Any custom universe filters

### Document Issues
If you find any problems:
1. Note what's not working
2. Check if it's related to missing data or a bug
3. Old table still available for rollback if needed

---

## üóëÔ∏è Cleanup (After 24-48 Hours of Testing)

**Once you're 100% confident everything works:**

```bash
# This will free up 342GB of disk space
PGPASSWORD=doctrove_admin psql -h localhost -p 5434 -U doctrove_admin -d doctrove \
  -f /opt/arxivscope/cleanup_old_table.sql
```

**‚ö†Ô∏è WARNING**: This is **irreversible**! The old table will be permanently deleted.

**Before running**, verify:
- [ ] All application features working
- [ ] No missing data discovered
- [ ] No performance issues
- [ ] Frontend displaying correctly
- [ ] Search/filters working as expected
- [ ] You have a recent database backup (optional but recommended)

---

## üîÑ Rollback (If Needed)

**Only if serious issues are discovered and old table still exists:**

```sql
BEGIN;

-- Drop triggers from new table
DROP TRIGGER trigger_queue_2d_embeddings ON doctrove_papers;
DROP TRIGGER trigger_queue_openalex_details ON doctrove_papers;

-- Swap back to old table
ALTER TABLE doctrove_papers RENAME TO doctrove_papers_new_failed;
ALTER TABLE doctrove_papers_old RENAME TO doctrove_papers;

-- Rename indexes back (remove _old suffix)
ALTER INDEX doctrove_papers_pkey_old RENAME TO doctrove_papers_pkey;
ALTER INDEX doctrove_papers_doctrove_source_doctrove_source_id_key_old 
  RENAME TO doctrove_papers_doctrove_source_doctrove_source_id_key;
ALTER INDEX idx_doctrove_source_old RENAME TO idx_doctrove_source;
ALTER INDEX idx_doctrove_source_id_old RENAME TO idx_doctrove_source_id;
ALTER INDEX idx_doctrove_primary_date_old RENAME TO idx_doctrove_primary_date;
ALTER INDEX idx_papers_src_date_old RENAME TO idx_papers_src_date;
ALTER INDEX idx_papers_date_brin_old RENAME TO idx_papers_date_brin;
ALTER INDEX idx_papers_authors_old RENAME TO idx_papers_authors;
ALTER INDEX idx_doctrove_embedding_2d_old RENAME TO idx_doctrove_embedding_2d;
ALTER INDEX idx_papers_needing_2d_embeddings_old RENAME TO idx_papers_needing_2d_embeddings;
ALTER INDEX idx_papers_with_2d_embeddings_old RENAME TO idx_papers_with_2d_embeddings;
ALTER INDEX idx_papers_embedding_ivfflat_optimized_old RENAME TO idx_papers_embedding_ivfflat_optimized;

-- Add triggers back to old table
CREATE TRIGGER trigger_queue_2d_embeddings 
    AFTER INSERT OR UPDATE ON doctrove_papers 
    FOR EACH ROW 
    EXECUTE FUNCTION queue_paper_for_2d_embedding();

CREATE TRIGGER trigger_queue_openalex_details 
    AFTER INSERT ON doctrove_papers 
    FOR EACH ROW 
    EXECUTE FUNCTION queue_openalex_details_enrichment();

COMMIT;

-- Restart API
./stop_doctrove.sh
./start_doctrove.sh
```

---

## üìä Benefits You're Now Seeing

### Performance Improvements
- **86% fewer rows** (2.9M vs 20.7M)
- **95% less storage** (16GB vs 358GB)
- **Faster queries** - smaller indexes, better cache utilization
- **Faster VACUUM** - no bloat, clean table structure
- **Optimal indexes** - sized for actual dataset

### Maintenance Improvements
- **No dead tuples** - started with clean slate
- **Compact storage** - no wasted space
- **Focused dataset** - only arxiv and RAND data

### Application Benefits
- **Aligned with purpose** - database matches application focus
- **Simpler queries** - no need to exclude OpenAlex
- **Cleaner data model** - focused on relevant sources

---

## üìÅ Documentation

- **MIGRATION_COMPLETE.md** - Full migration summary and results
- **MIGRATION_GUIDE.md** - Original migration planning and procedures
- **DATABASE_CLEANING_PLAN.md** - Updated with completion status
- **NEXT_STEPS.md** - This file

---

## üÜò Getting Help

If you encounter issues:

1. **Check API logs**: `screen -r doctrove_api`
2. **Check database**: Run verification queries above
3. **Check disk space**: `df -h`
4. **Review migration log**: All output was shown during migration

---

**Status**: Migration successful, ready for testing! üéâ



